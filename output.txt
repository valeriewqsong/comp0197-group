cpu
num labeled_data: 3680
num unlabeled_data: 0
train labeled dataset: 3680
train unlabeled dataset: 0
test labeled dataset: 3669
train labeled loader: 3676
train unlabeled loader: does not exist
test labeled loader: 3669
All the data is labeled.
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.720484
Epoch 1, iteration 20: loss = 0.655449
Epoch 1, iteration 30: loss = 0.673192
Epoch 1, iteration 40: loss = 0.664478
Epoch 1, iteration 50: loss = 0.676093
Epoch 1, iteration 60: loss = 0.679901
Epoch 1, iteration 70: loss = 0.666965
Epoch 1, iteration 80: loss = 0.667971
Epoch 1, iteration 90: loss = 0.668445
Epoch 1, iteration 100: loss = 0.665541
Epoch 1, iteration 110: loss = 0.663576
Epoch 1, iteration 120: loss = 0.635556
Epoch 1, iteration 130: loss = 0.653755
Epoch 1, iteration 140: loss = 0.642532
Epoch 1, iteration 150: loss = 0.644551
Epoch 1, iteration 160: loss = 0.629309
Epoch 1, iteration 170: loss = 0.646910
Epoch 1, iteration 180: loss = 0.678988
Epoch 1, iteration 190: loss = 0.647181
Epoch 1, iteration 200: loss = 0.646725
Epoch 1, iteration 210: loss = 0.650276
Epoch 1, iteration 220: loss = 0.641476
Epoch 1, iteration 230: loss = 0.636039
Epoch 1, iteration 240: loss = 0.631686
Epoch 1, iteration 250: loss = 0.630501
Epoch 1, iteration 260: loss = 0.623599
Epoch 1, iteration 270: loss = 0.644429
Epoch 1, iteration 280: loss = 0.663391
Epoch 1, iteration 290: loss = 0.624665
Epoch 1, iteration 300: loss = 0.634481
Epoch 1, iteration 310: loss = 0.641312
Epoch 1, iteration 320: loss = 0.621399
Epoch 1, iteration 330: loss = 0.625991
Epoch 1, iteration 340: loss = 0.627398
Epoch 1, iteration 350: loss = 0.644932
Epoch 1, iteration 360: loss = 0.628260
Epoch 1, iteration 370: loss = 0.616349
Epoch 1, iteration 380: loss = 0.620330
Epoch 1, iteration 390: loss = 0.618831
Epoch 1, iteration 400: loss = 0.615136
Epoch 1, iteration 410: loss = 0.619924
Epoch 1, iteration 420: loss = 0.613490
Epoch 1, iteration 430: loss = 0.609394
Epoch 1, iteration 440: loss = 0.617655
Epoch 1, iteration 450: loss = 0.608338
Epoch 1, iteration 460: loss = 0.617499
Epoch 1, iteration 470: loss = 0.597083
Epoch 1, iteration 480: loss = 0.608491
Epoch 1, iteration 490: loss = 0.609654
Epoch 1, iteration 500: loss = 0.612552
Epoch 1, iteration 510: loss = 0.610710
Epoch 1, iteration 520: loss = 0.610812
Epoch 1, iteration 530: loss = 0.601149
Epoch 1, iteration 540: loss = 0.617863
Epoch 1, iteration 550: loss = 0.618185
Epoch 1, iteration 560: loss = 0.607512
Epoch 1, iteration 570: loss = 0.617071
Epoch 1, iteration 580: loss = 0.621346
Epoch 1, iteration 590: loss = 0.629739
Epoch 1, iteration 600: loss = 0.647687
Epoch 1, iteration 610: loss = 0.632272
Epoch 1, iteration 620: loss = 0.617904
Epoch 1, iteration 630: loss = 0.619095
Epoch 1, iteration 640: loss = 0.615223
Epoch 1, iteration 650: loss = 0.630748
Epoch 1, iteration 660: loss = 0.636314
Epoch 1, iteration 670: loss = 0.600739
Epoch 1, iteration 680: loss = 0.620521
Epoch 1, iteration 690: loss = 0.606987
Epoch 1, iteration 700: loss = 0.616068
Epoch 1, iteration 710: loss = 0.611136
Epoch 1, iteration 720: loss = 0.648680
Epoch 1, iteration 730: loss = 0.611871
Epoch 1, iteration 740: loss = 0.628622
Epoch 1, iteration 750: loss = 0.600777
Epoch 1, iteration 760: loss = 0.596296
Epoch 1, iteration 770: loss = 0.623958
Epoch 1, iteration 780: loss = 0.615829
Epoch 1, iteration 790: loss = 0.610906
Epoch 1, iteration 800: loss = 0.605024
Epoch 1, iteration 810: loss = 0.619990
Epoch 1, iteration 820: loss = 0.603310
Epoch 1, iteration 830: loss = 0.600468
Epoch 1, iteration 840: loss = 0.590778
Epoch 1, iteration 850: loss = 0.605568
Epoch 1, iteration 860: loss = 0.600720
Epoch 1, iteration 870: loss = 0.614383
Epoch 1, iteration 880: loss = 0.619634
Epoch 1, iteration 890: loss = 0.602079
Epoch 1, iteration 900: loss = 0.594857
Epoch 1, iteration 910: loss = 0.607502
Epoch 1, iteration 920: loss = 0.589752
Epoch 1, Test Loss: 0.597573 IoU Score: 0.402427
Epoch 2, iteration 10: loss = 0.653110
Epoch 2, iteration 20: loss = 0.677973
Epoch 2, iteration 30: loss = 0.684190
Epoch 2, iteration 40: loss = 0.678187
Epoch 2, iteration 50: loss = 0.692410
Epoch 2, iteration 60: loss = 0.663743
Epoch 2, iteration 70: loss = 0.694317
Epoch 2, iteration 80: loss = 0.702009
Epoch 2, iteration 90: loss = 0.711337
Epoch 2, iteration 100: loss = 0.697305
Epoch 2, iteration 110: loss = 0.670091
Epoch 2, iteration 120: loss = 0.659851
Epoch 2, iteration 130: loss = 0.678742
Epoch 2, iteration 140: loss = 0.678582
Epoch 2, iteration 150: loss = 0.681306
Epoch 2, iteration 160: loss = 0.688735
Epoch 2, iteration 170: loss = 0.694845
Epoch 2, iteration 180: loss = 0.680079
Epoch 2, iteration 190: loss = 0.695131
Epoch 2, iteration 200: loss = 0.690484
Epoch 2, iteration 210: loss = 0.673995
Epoch 2, iteration 220: loss = 0.682499
Epoch 2, iteration 230: loss = 0.666790
Epoch 2, iteration 240: loss = 0.659719
Epoch 2, iteration 250: loss = 0.699326
Epoch 2, iteration 260: loss = 0.686444
Epoch 2, iteration 270: loss = 0.671968
Epoch 2, iteration 280: loss = 0.696140
Epoch 2, iteration 290: loss = 0.704979
Epoch 2, iteration 300: loss = 0.682895
Epoch 2, iteration 310: loss = 0.657849
Epoch 2, iteration 320: loss = 0.673073
Epoch 2, iteration 330: loss = 0.683220
Epoch 2, iteration 340: loss = 0.664904
Epoch 2, iteration 350: loss = 0.679874
Epoch 2, iteration 360: loss = 0.668937
Epoch 2, iteration 370: loss = 0.685285
Epoch 2, iteration 380: loss = 0.682869
Epoch 2, iteration 390: loss = 0.668400
Epoch 2, iteration 400: loss = 0.692414
Epoch 2, iteration 410: loss = 0.676657
Epoch 2, iteration 420: loss = 0.670118
Epoch 2, iteration 430: loss = 0.678189
Epoch 2, iteration 440: loss = 0.679321
Epoch 2, iteration 450: loss = 0.688313
Epoch 2, iteration 460: loss = 0.676393
Epoch 2, iteration 470: loss = 0.687002
Epoch 2, iteration 480: loss = 0.693306
Epoch 2, iteration 490: loss = 0.671324
Epoch 2, iteration 500: loss = 0.693405
Epoch 2, iteration 510: loss = 0.684763
Epoch 2, iteration 520: loss = 0.676018
Epoch 2, iteration 530: loss = 0.668900
Epoch 2, iteration 540: loss = 0.670452
Epoch 2, iteration 550: loss = 0.689643
Epoch 2, iteration 560: loss = 0.686252
Epoch 2, iteration 570: loss = 0.668702
Epoch 2, iteration 580: loss = 0.679810
Epoch 2, iteration 590: loss = 0.666253
Epoch 2, iteration 600: loss = 0.670434
Epoch 2, iteration 610: loss = 0.665257
Epoch 2, iteration 620: loss = 0.658396
Epoch 2, iteration 630: loss = 0.683870
Epoch 2, iteration 640: loss = 0.689430
Epoch 2, iteration 650: loss = 0.664247
Epoch 2, iteration 660: loss = 0.683779
Epoch 2, iteration 670: loss = 0.671290
Epoch 2, iteration 680: loss = 0.679841
Epoch 2, iteration 690: loss = 0.680367
Epoch 2, iteration 700: loss = 0.672864
Epoch 2, iteration 710: loss = 0.675321
Epoch 2, iteration 720: loss = 0.676709
Epoch 2, iteration 730: loss = 0.671992
Epoch 2, iteration 740: loss = 0.685878
Epoch 2, iteration 750: loss = 0.684477
Epoch 2, iteration 760: loss = 0.683811
Epoch 2, iteration 770: loss = 0.689411
Epoch 2, iteration 780: loss = 0.698569
Epoch 2, iteration 790: loss = 0.700085
Epoch 2, iteration 800: loss = 0.683455
Epoch 2, iteration 810: loss = 0.704352
Epoch 2, iteration 820: loss = 0.685097
Epoch 2, iteration 830: loss = 0.707531
Epoch 2, iteration 840: loss = 0.689592
Epoch 2, iteration 850: loss = 0.665135
Epoch 2, iteration 860: loss = 0.696290
Epoch 2, iteration 870: loss = 0.669114
Epoch 2, iteration 880: loss = 0.694027
Epoch 2, iteration 890: loss = 0.673605
Epoch 2, iteration 900: loss = 0.680131
Epoch 2, iteration 910: loss = 0.688676
Epoch 2, iteration 920: loss = 0.677418
Epoch 2, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 3, iteration 10: loss = 0.688587
Epoch 3, iteration 20: loss = 0.691093
Epoch 3, iteration 30: loss = 0.708024
Epoch 3, iteration 40: loss = 0.690505
Epoch 3, iteration 50: loss = 0.680832
Epoch 3, iteration 60: loss = 0.709037
Epoch 3, iteration 70: loss = 0.668788
Epoch 3, iteration 80: loss = 0.688691
Epoch 3, iteration 90: loss = 0.689845
Epoch 3, iteration 100: loss = 0.685912
Epoch 3, iteration 110: loss = 0.705672
Epoch 3, iteration 120: loss = 0.685516
Epoch 3, iteration 130: loss = 0.681808
Epoch 3, iteration 140: loss = 0.684186
Epoch 3, iteration 150: loss = 0.660932
Epoch 3, iteration 160: loss = 0.675560
Epoch 3, iteration 170: loss = 0.680468
Epoch 3, iteration 180: loss = 0.696459
Epoch 3, iteration 190: loss = 0.687973
Epoch 3, iteration 200: loss = 0.679406
Epoch 3, iteration 210: loss = 0.674676
Epoch 3, iteration 220: loss = 0.686802
Epoch 3, iteration 230: loss = 0.680045
Epoch 3, iteration 240: loss = 0.677111
Epoch 3, iteration 250: loss = 0.687834
Epoch 3, iteration 260: loss = 0.659577
Epoch 3, iteration 270: loss = 0.670355
Epoch 3, iteration 280: loss = 0.661557
Epoch 3, iteration 290: loss = 0.665205
Epoch 3, iteration 300: loss = 0.658987
Epoch 3, iteration 310: loss = 0.692594
Epoch 3, iteration 320: loss = 0.672426
Epoch 3, iteration 330: loss = 0.679863
Epoch 3, iteration 340: loss = 0.668976
Epoch 3, iteration 350: loss = 0.696857
Epoch 3, iteration 360: loss = 0.687547
Epoch 3, iteration 370: loss = 0.685345
Epoch 3, iteration 380: loss = 0.682179
Epoch 3, iteration 390: loss = 0.685994
Epoch 3, iteration 400: loss = 0.650931
Epoch 3, iteration 410: loss = 0.679125
Epoch 3, iteration 420: loss = 0.690770
Epoch 3, iteration 430: loss = 0.675521
Epoch 3, iteration 440: loss = 0.684662
Epoch 3, iteration 450: loss = 0.672323
Epoch 3, iteration 460: loss = 0.669056
Epoch 3, iteration 470: loss = 0.692618
Epoch 3, iteration 480: loss = 0.690307
Epoch 3, iteration 490: loss = 0.673379
Epoch 3, iteration 500: loss = 0.693865
Epoch 3, iteration 510: loss = 0.669441
Epoch 3, iteration 520: loss = 0.660152
Epoch 3, iteration 530: loss = 0.689016
Epoch 3, iteration 540: loss = 0.667439
Epoch 3, iteration 550: loss = 0.676409
Epoch 3, iteration 560: loss = 0.690549
Epoch 3, iteration 570: loss = 0.661856
Epoch 3, iteration 580: loss = 0.696935
Epoch 3, iteration 590: loss = 0.674764
Epoch 3, iteration 600: loss = 0.669052
Epoch 3, iteration 610: loss = 0.680724
Epoch 3, iteration 620: loss = 0.681992
Epoch 3, iteration 630: loss = 0.700219
Epoch 3, iteration 640: loss = 0.682577
Epoch 3, iteration 650: loss = 0.654581
Epoch 3, iteration 660: loss = 0.691673
Epoch 3, iteration 670: loss = 0.686376
Epoch 3, iteration 680: loss = 0.667541
Epoch 3, iteration 690: loss = 0.699810
Epoch 3, iteration 700: loss = 0.673762
Epoch 3, iteration 710: loss = 0.689659
Epoch 3, iteration 720: loss = 0.673924
Epoch 3, iteration 730: loss = 0.639468
Epoch 3, iteration 740: loss = 0.687788
Epoch 3, iteration 750: loss = 0.668271
Epoch 3, iteration 760: loss = 0.697037
Epoch 3, iteration 770: loss = 0.681986
Epoch 3, iteration 780: loss = 0.670763
Epoch 3, iteration 790: loss = 0.677774
Epoch 3, iteration 800: loss = 0.673432
Epoch 3, iteration 810: loss = 0.699133
Epoch 3, iteration 820: loss = 0.684385
Epoch 3, iteration 830: loss = 0.689404
Epoch 3, iteration 840: loss = 0.663642
Epoch 3, iteration 850: loss = 0.712755
Epoch 3, iteration 860: loss = 0.681472
Epoch 3, iteration 870: loss = 0.664385
Epoch 3, iteration 880: loss = 0.679935
Epoch 3, iteration 890: loss = 0.700239
Epoch 3, iteration 900: loss = 0.710651
Epoch 3, iteration 910: loss = 0.693223
Epoch 3, iteration 920: loss = 0.694929
Epoch 3, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 4, iteration 10: loss = 0.685836
Epoch 4, iteration 20: loss = 0.680420
Epoch 4, iteration 30: loss = 0.707276
Epoch 4, iteration 40: loss = 0.661278
Epoch 4, iteration 50: loss = 0.668026
Epoch 4, iteration 60: loss = 0.699213
Epoch 4, iteration 70: loss = 0.679470
Epoch 4, iteration 80: loss = 0.713165
Epoch 4, iteration 90: loss = 0.664230
Epoch 4, iteration 100: loss = 0.665119
Epoch 4, iteration 110: loss = 0.658229
Epoch 4, iteration 120: loss = 0.690728
Epoch 4, iteration 130: loss = 0.668002
Epoch 4, iteration 140: loss = 0.660942
Epoch 4, iteration 150: loss = 0.661378
Epoch 4, iteration 160: loss = 0.690191
Epoch 4, iteration 170: loss = 0.677055
Epoch 4, iteration 180: loss = 0.687494
Epoch 4, iteration 190: loss = 0.650932
Epoch 4, iteration 200: loss = 0.679270
Epoch 4, iteration 210: loss = 0.655560
Epoch 4, iteration 220: loss = 0.713786
Epoch 4, iteration 230: loss = 0.670400
Epoch 4, iteration 240: loss = 0.680310
Epoch 4, iteration 250: loss = 0.663353
Epoch 4, iteration 260: loss = 0.685327
Epoch 4, iteration 270: loss = 0.698046
Epoch 4, iteration 280: loss = 0.706728
Epoch 4, iteration 290: loss = 0.708882
Epoch 4, iteration 300: loss = 0.700826
Epoch 4, iteration 310: loss = 0.682335
Epoch 4, iteration 320: loss = 0.660191
Epoch 4, iteration 330: loss = 0.685483
Epoch 4, iteration 340: loss = 0.669803
Epoch 4, iteration 350: loss = 0.697737
Epoch 4, iteration 360: loss = 0.671813
Epoch 4, iteration 370: loss = 0.672976
Epoch 4, iteration 380: loss = 0.672840
Epoch 4, iteration 390: loss = 0.669447
Epoch 4, iteration 400: loss = 0.673080
Epoch 4, iteration 410: loss = 0.691096
Epoch 4, iteration 420: loss = 0.705663
Epoch 4, iteration 430: loss = 0.665130
Epoch 4, iteration 440: loss = 0.665243
Epoch 4, iteration 450: loss = 0.687399
Epoch 4, iteration 460: loss = 0.708808
Epoch 4, iteration 470: loss = 0.675163
Epoch 4, iteration 480: loss = 0.688194
Epoch 4, iteration 490: loss = 0.669031
Epoch 4, iteration 500: loss = 0.676338
Epoch 4, iteration 510: loss = 0.691967
Epoch 4, iteration 520: loss = 0.683390
Epoch 4, iteration 530: loss = 0.676305
Epoch 4, iteration 540: loss = 0.691430
Epoch 4, iteration 550: loss = 0.708174
Epoch 4, iteration 560: loss = 0.696756
Epoch 4, iteration 570: loss = 0.680033
Epoch 4, iteration 580: loss = 0.685332
Epoch 4, iteration 590: loss = 0.684689
Epoch 4, iteration 600: loss = 0.672329
Epoch 4, iteration 610: loss = 0.673959
Epoch 4, iteration 620: loss = 0.671002
Epoch 4, iteration 630: loss = 0.698936
Epoch 4, iteration 640: loss = 0.650875
Epoch 4, iteration 650: loss = 0.677456
Epoch 4, iteration 660: loss = 0.684814
Epoch 4, iteration 670: loss = 0.680838
Epoch 4, iteration 680: loss = 0.665682
Epoch 4, iteration 690: loss = 0.666256
Epoch 4, iteration 700: loss = 0.667314
Epoch 4, iteration 710: loss = 0.677681
Epoch 4, iteration 720: loss = 0.687779
Epoch 4, iteration 730: loss = 0.675883
Epoch 4, iteration 740: loss = 0.670964
Epoch 4, iteration 750: loss = 0.678637
Epoch 4, iteration 760: loss = 0.675433
Epoch 4, iteration 770: loss = 0.688785
Epoch 4, iteration 780: loss = 0.684147
Epoch 4, iteration 790: loss = 0.687967
Epoch 4, iteration 800: loss = 0.664338
Epoch 4, iteration 810: loss = 0.681469
Epoch 4, iteration 820: loss = 0.701155
Epoch 4, iteration 830: loss = 0.680971
Epoch 4, iteration 840: loss = 0.679698
Epoch 4, iteration 850: loss = 0.719930
Epoch 4, iteration 860: loss = 0.710400
Epoch 4, iteration 870: loss = 0.681544
Epoch 4, iteration 880: loss = 0.666114
Epoch 4, iteration 890: loss = 0.691328
Epoch 4, iteration 900: loss = 0.697023
Epoch 4, iteration 910: loss = 0.681063
Epoch 4, iteration 920: loss = 0.685814
Epoch 4, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 5, iteration 10: loss = 0.679883
Epoch 5, iteration 20: loss = 0.696979
Epoch 5, iteration 30: loss = 0.678119
Epoch 5, iteration 40: loss = 0.676587
Epoch 5, iteration 50: loss = 0.693202
Epoch 5, iteration 60: loss = 0.662576
Epoch 5, iteration 70: loss = 0.696065
Epoch 5, iteration 80: loss = 0.678788
Epoch 5, iteration 90: loss = 0.702454
Epoch 5, iteration 100: loss = 0.688618
Epoch 5, iteration 110: loss = 0.668936
Epoch 5, iteration 120: loss = 0.670922
Epoch 5, iteration 130: loss = 0.681302
Epoch 5, iteration 140: loss = 0.690772
Epoch 5, iteration 150: loss = 0.693780
Epoch 5, iteration 160: loss = 0.683221
Epoch 5, iteration 170: loss = 0.684928
Epoch 5, iteration 180: loss = 0.687024
Epoch 5, iteration 190: loss = 0.664298
Epoch 5, iteration 200: loss = 0.649927
Epoch 5, iteration 210: loss = 0.675965
Epoch 5, iteration 220: loss = 0.693108
Epoch 5, iteration 230: loss = 0.677548
Epoch 5, iteration 240: loss = 0.680718
Epoch 5, iteration 250: loss = 0.685060
Epoch 5, iteration 260: loss = 0.669864
Epoch 5, iteration 270: loss = 0.686712
Epoch 5, iteration 280: loss = 0.675570
Epoch 5, iteration 290: loss = 0.695612
Epoch 5, iteration 300: loss = 0.689508
Epoch 5, iteration 310: loss = 0.670310
Epoch 5, iteration 320: loss = 0.683475
Epoch 5, iteration 330: loss = 0.689474
Epoch 5, iteration 340: loss = 0.683948
Epoch 5, iteration 350: loss = 0.674464
Epoch 5, iteration 360: loss = 0.690765
Epoch 5, iteration 370: loss = 0.694305
Epoch 5, iteration 380: loss = 0.686964
Epoch 5, iteration 390: loss = 0.687409
Epoch 5, iteration 400: loss = 0.689985
Epoch 5, iteration 410: loss = 0.681199
Epoch 5, iteration 420: loss = 0.667263
Epoch 5, iteration 430: loss = 0.664664
Epoch 5, iteration 440: loss = 0.665152
Epoch 5, iteration 450: loss = 0.665378
Epoch 5, iteration 460: loss = 0.664890
Epoch 5, iteration 470: loss = 0.685111
Epoch 5, iteration 480: loss = 0.711280
Epoch 5, iteration 490: loss = 0.675735
Epoch 5, iteration 500: loss = 0.707548
Epoch 5, iteration 510: loss = 0.683399
Epoch 5, iteration 520: loss = 0.685031
Epoch 5, iteration 530: loss = 0.665328
Epoch 5, iteration 540: loss = 0.675457
Epoch 5, iteration 550: loss = 0.693146
Epoch 5, iteration 560: loss = 0.669312
Epoch 5, iteration 570: loss = 0.683634
Epoch 5, iteration 580: loss = 0.685242
Epoch 5, iteration 590: loss = 0.701918
Epoch 5, iteration 600: loss = 0.677520
Epoch 5, iteration 610: loss = 0.673123
Epoch 5, iteration 620: loss = 0.687618
Epoch 5, iteration 630: loss = 0.659893
Epoch 5, iteration 640: loss = 0.671126
Epoch 5, iteration 650: loss = 0.691273
Epoch 5, iteration 660: loss = 0.678068
Epoch 5, iteration 670: loss = 0.687801
Epoch 5, iteration 680: loss = 0.668817
Epoch 5, iteration 690: loss = 0.693189
Epoch 5, iteration 700: loss = 0.662329
Epoch 5, iteration 710: loss = 0.681978
Epoch 5, iteration 720: loss = 0.706353
Epoch 5, iteration 730: loss = 0.675078
Epoch 5, iteration 740: loss = 0.665970
Epoch 5, iteration 750: loss = 0.696011
Epoch 5, iteration 760: loss = 0.666310
Epoch 5, iteration 770: loss = 0.675598
Epoch 5, iteration 780: loss = 0.637781
Epoch 5, iteration 790: loss = 0.702944
Epoch 5, iteration 800: loss = 0.699184
Epoch 5, iteration 810: loss = 0.684662
Epoch 5, iteration 820: loss = 0.705316
Epoch 5, iteration 830: loss = 0.681458
Epoch 5, iteration 840: loss = 0.684967
Epoch 5, iteration 850: loss = 0.674499
Epoch 5, iteration 860: loss = 0.678862
Epoch 5, iteration 870: loss = 0.687653
Epoch 5, iteration 880: loss = 0.658496
Epoch 5, iteration 890: loss = 0.687761
Epoch 5, iteration 900: loss = 0.703964
Epoch 5, iteration 910: loss = 0.665042
Epoch 5, iteration 920: loss = 0.684426
Epoch 5, Test Loss: 0.677774 IoU Score: 0.322226
Training completed.
Model trained with iou loss and all labeled data saved.
num labeled_data: 1840
num unlabeled_data: 1840
train labeled dataset: 1840
train unlabeled dataset: 1840
test labeled dataset: 3669
train labeled loader: 1836
train unlabeled loader: 1836
test labeled loader: 3669
Equal split, ratio of labeled to unlabeled data is 1:1
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.736621 alpha = 0
Epoch 1, iteration 20: loss = 0.713189 alpha = 0
Epoch 1, iteration 30: loss = 0.708248 alpha = 0
Epoch 1, iteration 40: loss = 0.706676 alpha = 0
Epoch 1, iteration 50: loss = 0.707154 alpha = 0
Epoch 1, iteration 60: loss = 0.713587 alpha = 0
Epoch 1, iteration 70: loss = 0.708064 alpha = 0
Epoch 1, iteration 80: loss = 0.711619 alpha = 0
Epoch 1, iteration 90: loss = 0.723480 alpha = 0
Epoch 1, iteration 100: loss = 0.722664 alpha = 0
Epoch 1, iteration 110: loss = 0.704447 alpha = 0.018
Epoch 1, iteration 120: loss = 0.736691 alpha = 0.038
Epoch 1, iteration 130: loss = 0.729078 alpha = 0.058
Epoch 1, iteration 140: loss = 0.771682 alpha = 0.078
Epoch 1, iteration 150: loss = 0.756194 alpha = 0.098
Epoch 1, iteration 160: loss = 0.767326 alpha = 0.118
Epoch 1, iteration 170: loss = 0.781651 alpha = 0.138
Epoch 1, iteration 180: loss = 0.787670 alpha = 0.158
Epoch 1, iteration 190: loss = 0.809559 alpha = 0.178
Epoch 1, iteration 200: loss = 0.790961 alpha = 0.198
Epoch 1, iteration 210: loss = 0.818405 alpha = 0.218
Epoch 1, iteration 220: loss = 0.822640 alpha = 0.238
Epoch 1, iteration 230: loss = 0.848005 alpha = 0.258
Epoch 1, iteration 240: loss = 0.853582 alpha = 0.278
Epoch 1, iteration 250: loss = 0.844367 alpha = 0.298
Epoch 1, iteration 260: loss = 0.861468 alpha = 0.318
Epoch 1, iteration 270: loss = 0.896089 alpha = 0.338
Epoch 1, iteration 280: loss = 0.871136 alpha = 0.358
Epoch 1, iteration 290: loss = 0.875597 alpha = 0.378
Epoch 1, iteration 300: loss = 0.890715 alpha = 0.398
Epoch 1, iteration 310: loss = 0.939162 alpha = 0.418
Epoch 1, iteration 320: loss = 0.932498 alpha = 0.438
Epoch 1, iteration 330: loss = 0.958557 alpha = 0.458
Epoch 1, iteration 340: loss = 0.955087 alpha = 0.478
Epoch 1, iteration 350: loss = 0.980121 alpha = 0.498
Epoch 1, iteration 360: loss = 0.950340 alpha = 0.518
Epoch 1, iteration 370: loss = 0.974440 alpha = 0.538
Epoch 1, iteration 380: loss = 0.971496 alpha = 0.558
Epoch 1, iteration 390: loss = 1.005364 alpha = 0.578
Epoch 1, iteration 400: loss = 0.987638 alpha = 0.598
Epoch 1, iteration 410: loss = 1.030070 alpha = 0.618
Epoch 1, iteration 420: loss = 1.005588 alpha = 0.638
Epoch 1, iteration 430: loss = 1.036637 alpha = 0.658
Epoch 1, iteration 440: loss = 1.041408 alpha = 0.678
Epoch 1, iteration 450: loss = 1.041617 alpha = 0.698
Epoch 1, iteration 460: loss = 1.055833 alpha = 0.718
Epoch 1, Test Loss: 0.637434 IoU Score: 0.362566
Epoch 2, iteration 10: loss = 0.718968 alpha = 0
Epoch 2, iteration 20: loss = 0.717151 alpha = 0
Epoch 2, iteration 30: loss = 0.714610 alpha = 0
Epoch 2, iteration 40: loss = 0.715722 alpha = 0
Epoch 2, iteration 50: loss = 0.739179 alpha = 0
Epoch 2, iteration 60: loss = 0.725915 alpha = 0
Epoch 2, iteration 70: loss = 0.719599 alpha = 0
Epoch 2, iteration 80: loss = 0.687058 alpha = 0
Epoch 2, iteration 90: loss = 0.697463 alpha = 0
Epoch 2, iteration 100: loss = 0.721472 alpha = 0
Epoch 2, iteration 110: loss = 0.725351 alpha = 0.018
Epoch 2, iteration 120: loss = 0.725582 alpha = 0.038
Epoch 2, iteration 130: loss = 0.756706 alpha = 0.058
Epoch 2, iteration 140: loss = 0.764208 alpha = 0.078
Epoch 2, iteration 150: loss = 0.756015 alpha = 0.098
Epoch 2, iteration 160: loss = 0.783626 alpha = 0.118
Epoch 2, iteration 170: loss = 0.792317 alpha = 0.138
Epoch 2, iteration 180: loss = 0.793773 alpha = 0.158
Epoch 2, iteration 190: loss = 0.792330 alpha = 0.178
Epoch 2, iteration 200: loss = 0.806497 alpha = 0.198
Epoch 2, iteration 210: loss = 0.831342 alpha = 0.218
Epoch 2, iteration 220: loss = 0.839763 alpha = 0.238
Epoch 2, iteration 230: loss = 0.855644 alpha = 0.258
Epoch 2, iteration 240: loss = 0.853458 alpha = 0.278
Epoch 2, iteration 250: loss = 0.876078 alpha = 0.298
Epoch 2, iteration 260: loss = 0.856731 alpha = 0.318
Epoch 2, iteration 270: loss = 0.903412 alpha = 0.338
Epoch 2, iteration 280: loss = 0.889935 alpha = 0.358
Epoch 2, iteration 290: loss = 0.913995 alpha = 0.378
Epoch 2, iteration 300: loss = 0.924799 alpha = 0.398
Epoch 2, iteration 310: loss = 0.929171 alpha = 0.418
Epoch 2, iteration 320: loss = 0.903739 alpha = 0.438
Epoch 2, iteration 330: loss = 0.961913 alpha = 0.458
Epoch 2, iteration 340: loss = 0.943608 alpha = 0.478
Epoch 2, iteration 350: loss = 0.951647 alpha = 0.498
Epoch 2, iteration 360: loss = 0.973097 alpha = 0.518
Epoch 2, iteration 370: loss = 0.992390 alpha = 0.538
Epoch 2, iteration 380: loss = 0.982624 alpha = 0.558
Epoch 2, iteration 390: loss = 1.019069 alpha = 0.578
Epoch 2, iteration 400: loss = 1.009069 alpha = 0.598
Epoch 2, iteration 410: loss = 1.025537 alpha = 0.618
Epoch 2, iteration 420: loss = 1.040118 alpha = 0.638
Epoch 2, iteration 430: loss = 1.039763 alpha = 0.658
Epoch 2, iteration 440: loss = 1.046587 alpha = 0.678
Epoch 2, iteration 450: loss = 1.056970 alpha = 0.698
Epoch 2, iteration 460: loss = 1.047797 alpha = 0.718
Epoch 2, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 3, iteration 10: loss = 0.713880 alpha = 0
Epoch 3, iteration 20: loss = 0.709164 alpha = 0
Epoch 3, iteration 30: loss = 0.734855 alpha = 0
Epoch 3, iteration 40: loss = 0.719270 alpha = 0
Epoch 3, iteration 50: loss = 0.717081 alpha = 0
Epoch 3, iteration 60: loss = 0.709365 alpha = 0
Epoch 3, iteration 70: loss = 0.720659 alpha = 0
Epoch 3, iteration 80: loss = 0.705326 alpha = 0
Epoch 3, iteration 90: loss = 0.717763 alpha = 0
Epoch 3, iteration 100: loss = 0.731221 alpha = 0
Epoch 3, iteration 110: loss = 0.745659 alpha = 0.018
Epoch 3, iteration 120: loss = 0.732929 alpha = 0.038
Epoch 3, iteration 130: loss = 0.739429 alpha = 0.058
Epoch 3, iteration 140: loss = 0.743253 alpha = 0.078
Epoch 3, iteration 150: loss = 0.768217 alpha = 0.098
Epoch 3, iteration 160: loss = 0.788778 alpha = 0.118
Epoch 3, iteration 170: loss = 0.796841 alpha = 0.138
Epoch 3, iteration 180: loss = 0.776523 alpha = 0.158
Epoch 3, iteration 190: loss = 0.801576 alpha = 0.178
Epoch 3, iteration 200: loss = 0.812837 alpha = 0.198
Epoch 3, iteration 210: loss = 0.835424 alpha = 0.218
Epoch 3, iteration 220: loss = 0.813288 alpha = 0.238
Epoch 3, iteration 230: loss = 0.828754 alpha = 0.258
Epoch 3, iteration 240: loss = 0.849221 alpha = 0.278
Epoch 3, iteration 250: loss = 0.874157 alpha = 0.298
Epoch 3, iteration 260: loss = 0.883689 alpha = 0.318
Epoch 3, iteration 270: loss = 0.879391 alpha = 0.338
Epoch 3, iteration 280: loss = 0.876930 alpha = 0.358
Epoch 3, iteration 290: loss = 0.910057 alpha = 0.378
Epoch 3, iteration 300: loss = 0.931489 alpha = 0.398
Epoch 3, iteration 310: loss = 0.915525 alpha = 0.418
Epoch 3, iteration 320: loss = 0.921859 alpha = 0.438
Epoch 3, iteration 330: loss = 0.947729 alpha = 0.458
Epoch 3, iteration 340: loss = 0.955895 alpha = 0.478
Epoch 3, iteration 350: loss = 0.976486 alpha = 0.498
Epoch 3, iteration 360: loss = 0.962718 alpha = 0.518
Epoch 3, iteration 370: loss = 0.968105 alpha = 0.538
Epoch 3, iteration 380: loss = 0.985032 alpha = 0.558
Epoch 3, iteration 390: loss = 0.980710 alpha = 0.578
Epoch 3, iteration 400: loss = 1.022844 alpha = 0.598
Epoch 3, iteration 410: loss = 1.036322 alpha = 0.618
Epoch 3, iteration 420: loss = 1.043780 alpha = 0.638
Epoch 3, iteration 430: loss = 1.040144 alpha = 0.658
Epoch 3, iteration 440: loss = 1.035589 alpha = 0.678
Epoch 3, iteration 450: loss = 1.075937 alpha = 0.698
Epoch 3, iteration 460: loss = 1.082971 alpha = 0.718
Epoch 3, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 4, iteration 10: loss = 0.720778 alpha = 0
Epoch 4, iteration 20: loss = 0.699068 alpha = 0
Epoch 4, iteration 30: loss = 0.713381 alpha = 0
Epoch 4, iteration 40: loss = 0.717313 alpha = 0
Epoch 4, iteration 50: loss = 0.707029 alpha = 0
Epoch 4, iteration 60: loss = 0.703232 alpha = 0
Epoch 4, iteration 70: loss = 0.708492 alpha = 0
Epoch 4, iteration 80: loss = 0.720689 alpha = 0
Epoch 4, iteration 90: loss = 0.722396 alpha = 0
Epoch 4, iteration 100: loss = 0.729201 alpha = 0
Epoch 4, iteration 110: loss = 0.723673 alpha = 0.018
Epoch 4, iteration 120: loss = 0.723817 alpha = 0.038
Epoch 4, iteration 130: loss = 0.752153 alpha = 0.058
Epoch 4, iteration 140: loss = 0.763947 alpha = 0.078
Epoch 4, iteration 150: loss = 0.772579 alpha = 0.098
Epoch 4, iteration 160: loss = 0.777120 alpha = 0.118
Epoch 4, iteration 170: loss = 0.775562 alpha = 0.138
Epoch 4, iteration 180: loss = 0.793639 alpha = 0.158
Epoch 4, iteration 190: loss = 0.804889 alpha = 0.178
Epoch 4, iteration 200: loss = 0.804628 alpha = 0.198
Epoch 4, iteration 210: loss = 0.823593 alpha = 0.218
Epoch 4, iteration 220: loss = 0.834156 alpha = 0.238
Epoch 4, iteration 230: loss = 0.857891 alpha = 0.258
Epoch 4, iteration 240: loss = 0.857318 alpha = 0.278
Epoch 4, iteration 250: loss = 0.863247 alpha = 0.298
Epoch 4, iteration 260: loss = 0.871750 alpha = 0.318
Epoch 4, iteration 270: loss = 0.880582 alpha = 0.338
Epoch 4, iteration 280: loss = 0.910185 alpha = 0.358
Epoch 4, iteration 290: loss = 0.908103 alpha = 0.378
Epoch 4, iteration 300: loss = 0.907909 alpha = 0.398
Epoch 4, iteration 310: loss = 0.915096 alpha = 0.418
Epoch 4, iteration 320: loss = 0.924497 alpha = 0.438
Epoch 4, iteration 330: loss = 0.942135 alpha = 0.458
Epoch 4, iteration 340: loss = 0.960855 alpha = 0.478
Epoch 4, iteration 350: loss = 0.949003 alpha = 0.498
Epoch 4, iteration 360: loss = 0.986069 alpha = 0.518
Epoch 4, iteration 370: loss = 0.986299 alpha = 0.538
Epoch 4, iteration 380: loss = 0.983534 alpha = 0.558
Epoch 4, iteration 390: loss = 1.017451 alpha = 0.578
Epoch 4, iteration 400: loss = 1.007639 alpha = 0.598
Epoch 4, iteration 410: loss = 1.017000 alpha = 0.618
Epoch 4, iteration 420: loss = 1.036995 alpha = 0.638
Epoch 4, iteration 430: loss = 1.037922 alpha = 0.658
Epoch 4, iteration 440: loss = 1.056237 alpha = 0.678
Epoch 4, iteration 450: loss = 1.056102 alpha = 0.698
Epoch 4, iteration 460: loss = 1.093522 alpha = 0.718
Epoch 4, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 5, iteration 10: loss = 0.716246 alpha = 0
Epoch 5, iteration 20: loss = 0.737596 alpha = 0
Epoch 5, iteration 30: loss = 0.704744 alpha = 0
Epoch 5, iteration 40: loss = 0.711382 alpha = 0
Epoch 5, iteration 50: loss = 0.726809 alpha = 0
Epoch 5, iteration 60: loss = 0.712160 alpha = 0
Epoch 5, iteration 70: loss = 0.715402 alpha = 0
Epoch 5, iteration 80: loss = 0.718749 alpha = 0
Epoch 5, iteration 90: loss = 0.701979 alpha = 0
Epoch 5, iteration 100: loss = 0.726719 alpha = 0
Epoch 5, iteration 110: loss = 0.725909 alpha = 0.018
Epoch 5, iteration 120: loss = 0.732108 alpha = 0.038
Epoch 5, iteration 130: loss = 0.739035 alpha = 0.058
Epoch 5, iteration 140: loss = 0.765443 alpha = 0.078
Epoch 5, iteration 150: loss = 0.765909 alpha = 0.098
Epoch 5, iteration 160: loss = 0.762472 alpha = 0.118
Epoch 5, iteration 170: loss = 0.791572 alpha = 0.138
Epoch 5, iteration 180: loss = 0.792915 alpha = 0.158
Epoch 5, iteration 190: loss = 0.823298 alpha = 0.178
Epoch 5, iteration 200: loss = 0.794838 alpha = 0.198
Epoch 5, iteration 210: loss = 0.823988 alpha = 0.218
Epoch 5, iteration 220: loss = 0.827025 alpha = 0.238
Epoch 5, iteration 230: loss = 0.841098 alpha = 0.258
Epoch 5, iteration 240: loss = 0.857105 alpha = 0.278
Epoch 5, iteration 250: loss = 0.842791 alpha = 0.298
Epoch 5, iteration 260: loss = 0.871590 alpha = 0.318
Epoch 5, iteration 270: loss = 0.888883 alpha = 0.338
Epoch 5, iteration 280: loss = 0.885589 alpha = 0.358
Epoch 5, iteration 290: loss = 0.899169 alpha = 0.378
Epoch 5, iteration 300: loss = 0.900806 alpha = 0.398
Epoch 5, iteration 310: loss = 0.916351 alpha = 0.418
Epoch 5, iteration 320: loss = 0.949290 alpha = 0.438
Epoch 5, iteration 330: loss = 0.963953 alpha = 0.458
Epoch 5, iteration 340: loss = 0.939188 alpha = 0.478
Epoch 5, iteration 350: loss = 0.945333 alpha = 0.498
Epoch 5, iteration 360: loss = 0.976002 alpha = 0.518
Epoch 5, iteration 370: loss = 0.968540 alpha = 0.538
Epoch 5, iteration 380: loss = 0.989609 alpha = 0.558
Epoch 5, iteration 390: loss = 1.020543 alpha = 0.578
Epoch 5, iteration 400: loss = 1.025298 alpha = 0.598
Epoch 5, iteration 410: loss = 1.047504 alpha = 0.618
Epoch 5, iteration 420: loss = 1.054301 alpha = 0.638
Epoch 5, iteration 430: loss = 1.023076 alpha = 0.658
Epoch 5, iteration 440: loss = 1.059904 alpha = 0.678
Epoch 5, iteration 450: loss = 1.042295 alpha = 0.698
Epoch 5, iteration 460: loss = 1.094157 alpha = 0.718
Epoch 5, Test Loss: 0.677774 IoU Score: 0.322226
Training completed.
Model trained with iou loss and 1:1 ratio saved.
Equal split, ratio of labeled to unlabeled data is 1:1, but only labeled data is used here.
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.748624
Epoch 1, iteration 20: loss = 0.681097
Epoch 1, iteration 30: loss = 0.678985
Epoch 1, iteration 40: loss = 0.657789
Epoch 1, iteration 50: loss = 0.656557
Epoch 1, iteration 60: loss = 0.647172
Epoch 1, iteration 70: loss = 0.677026
Epoch 1, iteration 80: loss = 0.663736
Epoch 1, iteration 90: loss = 0.656258
Epoch 1, iteration 100: loss = 0.665312
Epoch 1, iteration 110: loss = 0.640587
Epoch 1, iteration 120: loss = 0.634118
Epoch 1, iteration 130: loss = 0.672204
Epoch 1, iteration 140: loss = 0.637020
Epoch 1, iteration 150: loss = 0.631413
Epoch 1, iteration 160: loss = 0.633712
Epoch 1, iteration 170: loss = 0.622697
Epoch 1, iteration 180: loss = 0.641481
Epoch 1, iteration 190: loss = 0.629419
Epoch 1, iteration 200: loss = 0.635141
Epoch 1, iteration 210: loss = 0.635786
Epoch 1, iteration 220: loss = 0.626899
Epoch 1, iteration 230: loss = 0.637468
Epoch 1, iteration 240: loss = 0.629569
Epoch 1, iteration 250: loss = 0.615864
Epoch 1, iteration 260: loss = 0.634215
Epoch 1, iteration 270: loss = 0.626154
Epoch 1, iteration 280: loss = 0.607572
Epoch 1, iteration 290: loss = 0.609852
Epoch 1, iteration 300: loss = 0.630054
Epoch 1, iteration 310: loss = 0.618152
Epoch 1, iteration 320: loss = 0.610122
Epoch 1, iteration 330: loss = 0.609626
Epoch 1, iteration 340: loss = 0.616629
Epoch 1, iteration 350: loss = 0.610816
Epoch 1, iteration 360: loss = 0.619946
Epoch 1, iteration 370: loss = 0.631187
Epoch 1, iteration 380: loss = 0.617211
Epoch 1, iteration 390: loss = 0.625238
Epoch 1, iteration 400: loss = 0.617183
Epoch 1, iteration 410: loss = 0.600925
Epoch 1, iteration 420: loss = 0.629376
Epoch 1, iteration 430: loss = 0.628361
Epoch 1, iteration 440: loss = 0.630534
Epoch 1, iteration 450: loss = 0.615502
Epoch 1, iteration 460: loss = 0.614876
Epoch 1, Test Loss: 0.608571 IoU Score: 0.391429
Epoch 2, iteration 10: loss = 0.629622
Epoch 2, iteration 20: loss = 0.663499
Epoch 2, iteration 30: loss = 0.692779
Epoch 2, iteration 40: loss = 0.678432
Epoch 2, iteration 50: loss = 0.655508
Epoch 2, iteration 60: loss = 0.686253
Epoch 2, iteration 70: loss = 0.696350
Epoch 2, iteration 80: loss = 0.703799
Epoch 2, iteration 90: loss = 0.689570
Epoch 2, iteration 100: loss = 0.715687
Epoch 2, iteration 110: loss = 0.696421
Epoch 2, iteration 120: loss = 0.700463
Epoch 2, iteration 130: loss = 0.669594
Epoch 2, iteration 140: loss = 0.664025
Epoch 2, iteration 150: loss = 0.653443
Epoch 2, iteration 160: loss = 0.700135
Epoch 2, iteration 170: loss = 0.655883
Epoch 2, iteration 180: loss = 0.673030
Epoch 2, iteration 190: loss = 0.680117
Epoch 2, iteration 200: loss = 0.682851
Epoch 2, iteration 210: loss = 0.684899
Epoch 2, iteration 220: loss = 0.686088
Epoch 2, iteration 230: loss = 0.707886
Epoch 2, iteration 240: loss = 0.675123
Epoch 2, iteration 250: loss = 0.664366
Epoch 2, iteration 260: loss = 0.708079
Epoch 2, iteration 270: loss = 0.688729
Epoch 2, iteration 280: loss = 0.669567
Epoch 2, iteration 290: loss = 0.675367
Epoch 2, iteration 300: loss = 0.686043
Epoch 2, iteration 310: loss = 0.673109
Epoch 2, iteration 320: loss = 0.695149
Epoch 2, iteration 330: loss = 0.699496
Epoch 2, iteration 340: loss = 0.689016
Epoch 2, iteration 350: loss = 0.695782
Epoch 2, iteration 360: loss = 0.662112
Epoch 2, iteration 370: loss = 0.686968
Epoch 2, iteration 380: loss = 0.679160
Epoch 2, iteration 390: loss = 0.733690
Epoch 2, iteration 400: loss = 0.665678
Epoch 2, iteration 410: loss = 0.680849
Epoch 2, iteration 420: loss = 0.705678
Epoch 2, iteration 430: loss = 0.672462
Epoch 2, iteration 440: loss = 0.665867
Epoch 2, iteration 450: loss = 0.647780
Epoch 2, iteration 460: loss = 0.689729
Epoch 2, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 3, iteration 10: loss = 0.656328
Epoch 3, iteration 20: loss = 0.672427
Epoch 3, iteration 30: loss = 0.687964
Epoch 3, iteration 40: loss = 0.689301
Epoch 3, iteration 50: loss = 0.669348
Epoch 3, iteration 60: loss = 0.671344
Epoch 3, iteration 70: loss = 0.661151
Epoch 3, iteration 80: loss = 0.683779
Epoch 3, iteration 90: loss = 0.680763
Epoch 3, iteration 100: loss = 0.672600
Epoch 3, iteration 110: loss = 0.670847
Epoch 3, iteration 120: loss = 0.684366
Epoch 3, iteration 130: loss = 0.699172
Epoch 3, iteration 140: loss = 0.706422
Epoch 3, iteration 150: loss = 0.658634
Epoch 3, iteration 160: loss = 0.704797
Epoch 3, iteration 170: loss = 0.679696
Epoch 3, iteration 180: loss = 0.700365
Epoch 3, iteration 190: loss = 0.677544
Epoch 3, iteration 200: loss = 0.689981
Epoch 3, iteration 210: loss = 0.688926
Epoch 3, iteration 220: loss = 0.675636
Epoch 3, iteration 230: loss = 0.679603
Epoch 3, iteration 240: loss = 0.675551
Epoch 3, iteration 250: loss = 0.668276
Epoch 3, iteration 260: loss = 0.700985
Epoch 3, iteration 270: loss = 0.710517
Epoch 3, iteration 280: loss = 0.667494
Epoch 3, iteration 290: loss = 0.689330
Epoch 3, iteration 300: loss = 0.686175
Epoch 3, iteration 310: loss = 0.687672
Epoch 3, iteration 320: loss = 0.695848
Epoch 3, iteration 330: loss = 0.676315
Epoch 3, iteration 340: loss = 0.695772
Epoch 3, iteration 350: loss = 0.686058
Epoch 3, iteration 360: loss = 0.663957
Epoch 3, iteration 370: loss = 0.712305
Epoch 3, iteration 380: loss = 0.684693
Epoch 3, iteration 390: loss = 0.665578
Epoch 3, iteration 400: loss = 0.682226
Epoch 3, iteration 410: loss = 0.694201
Epoch 3, iteration 420: loss = 0.669885
Epoch 3, iteration 430: loss = 0.705215
Epoch 3, iteration 440: loss = 0.704846
Epoch 3, iteration 450: loss = 0.688328
Epoch 3, iteration 460: loss = 0.665133
Epoch 3, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 4, iteration 10: loss = 0.676379
Epoch 4, iteration 20: loss = 0.669048
Epoch 4, iteration 30: loss = 0.691340
Epoch 4, iteration 40: loss = 0.692758
Epoch 4, iteration 50: loss = 0.679565
Epoch 4, iteration 60: loss = 0.706858
Epoch 4, iteration 70: loss = 0.687380
Epoch 4, iteration 80: loss = 0.689309
Epoch 4, iteration 90: loss = 0.686839
Epoch 4, iteration 100: loss = 0.649588
Epoch 4, iteration 110: loss = 0.713819
Epoch 4, iteration 120: loss = 0.708371
Epoch 4, iteration 130: loss = 0.659611
Epoch 4, iteration 140: loss = 0.666330
Epoch 4, iteration 150: loss = 0.689017
Epoch 4, iteration 160: loss = 0.688837
Epoch 4, iteration 170: loss = 0.673420
Epoch 4, iteration 180: loss = 0.698637
Epoch 4, iteration 190: loss = 0.690251
Epoch 4, iteration 200: loss = 0.692358
Epoch 4, iteration 210: loss = 0.679586
Epoch 4, iteration 220: loss = 0.666581
Epoch 4, iteration 230: loss = 0.692535
Epoch 4, iteration 240: loss = 0.685264
Epoch 4, iteration 250: loss = 0.679072
Epoch 4, iteration 260: loss = 0.664773
Epoch 4, iteration 270: loss = 0.705861
Epoch 4, iteration 280: loss = 0.674137
Epoch 4, iteration 290: loss = 0.669035
Epoch 4, iteration 300: loss = 0.710801
Epoch 4, iteration 310: loss = 0.687195
Epoch 4, iteration 320: loss = 0.678606
Epoch 4, iteration 330: loss = 0.681130
Epoch 4, iteration 340: loss = 0.692291
Epoch 4, iteration 350: loss = 0.700085
Epoch 4, iteration 360: loss = 0.673127
Epoch 4, iteration 370: loss = 0.690637
Epoch 4, iteration 380: loss = 0.665566
Epoch 4, iteration 390: loss = 0.665813
Epoch 4, iteration 400: loss = 0.692811
Epoch 4, iteration 410: loss = 0.697471
Epoch 4, iteration 420: loss = 0.694019
Epoch 4, iteration 430: loss = 0.662073
Epoch 4, iteration 440: loss = 0.666661
Epoch 4, iteration 450: loss = 0.648524
Epoch 4, iteration 460: loss = 0.703986
Epoch 4, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 5, iteration 10: loss = 0.698346
Epoch 5, iteration 20: loss = 0.663201
Epoch 5, iteration 30: loss = 0.670277
Epoch 5, iteration 40: loss = 0.689500
Epoch 5, iteration 50: loss = 0.668835
Epoch 5, iteration 60: loss = 0.678846
Epoch 5, iteration 70: loss = 0.687151
Epoch 5, iteration 80: loss = 0.663153
Epoch 5, iteration 90: loss = 0.688139
Epoch 5, iteration 100: loss = 0.690690
Epoch 5, iteration 110: loss = 0.700312
Epoch 5, iteration 120: loss = 0.687855
Epoch 5, iteration 130: loss = 0.702831
Epoch 5, iteration 140: loss = 0.675327
Epoch 5, iteration 150: loss = 0.690720
Epoch 5, iteration 160: loss = 0.670411
Epoch 5, iteration 170: loss = 0.696223
Epoch 5, iteration 180: loss = 0.665169
Epoch 5, iteration 190: loss = 0.692506
Epoch 5, iteration 200: loss = 0.685602
Epoch 5, iteration 210: loss = 0.676321
Epoch 5, iteration 220: loss = 0.684715
Epoch 5, iteration 230: loss = 0.698870
Epoch 5, iteration 240: loss = 0.673647
Epoch 5, iteration 250: loss = 0.655791
Epoch 5, iteration 260: loss = 0.679724
Epoch 5, iteration 270: loss = 0.686853
Epoch 5, iteration 280: loss = 0.686860
Epoch 5, iteration 290: loss = 0.695278
Epoch 5, iteration 300: loss = 0.667921
Epoch 5, iteration 310: loss = 0.698827
Epoch 5, iteration 320: loss = 0.698030
Epoch 5, iteration 330: loss = 0.668512
Epoch 5, iteration 340: loss = 0.703989
Epoch 5, iteration 350: loss = 0.661531
Epoch 5, iteration 360: loss = 0.702656
Epoch 5, iteration 370: loss = 0.682457
Epoch 5, iteration 380: loss = 0.669740
Epoch 5, iteration 390: loss = 0.693423
Epoch 5, iteration 400: loss = 0.676362
Epoch 5, iteration 410: loss = 0.669278
Epoch 5, iteration 420: loss = 0.696607
Epoch 5, iteration 430: loss = 0.667247
Epoch 5, iteration 440: loss = 0.699694
Epoch 5, iteration 450: loss = 0.675537
Epoch 5, iteration 460: loss = 0.702390
Epoch 5, Test Loss: 0.677774 IoU Score: 0.322226
Training completed.
Model trained with iou loss and 1:1 ratio but labeled only saved.
num labeled_data: 920
num unlabeled_data: 2760
train labeled dataset: 920
train unlabeled dataset: 2760
test labeled dataset: 3669
train labeled loader: 916
train unlabeled loader: 2748
test labeled loader: 3669
Ratio of labeled to unlabeled data is 1:3
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.739768 alpha = 0
Epoch 1, iteration 20: loss = 0.723975 alpha = 0
Epoch 1, iteration 30: loss = 0.710902 alpha = 0
Epoch 1, iteration 40: loss = 0.716381 alpha = 0
Epoch 1, iteration 50: loss = 0.724356 alpha = 0
Epoch 1, iteration 60: loss = 0.709263 alpha = 0
Epoch 1, iteration 70: loss = 0.710375 alpha = 0
Epoch 1, iteration 80: loss = 0.711043 alpha = 0
Epoch 1, iteration 90: loss = 0.720640 alpha = 0
Epoch 1, iteration 100: loss = 0.732609 alpha = 0
Epoch 1, iteration 110: loss = 0.704504 alpha = 0.018
Epoch 1, iteration 120: loss = 0.728637 alpha = 0.038
Epoch 1, iteration 130: loss = 0.737947 alpha = 0.058
Epoch 1, iteration 140: loss = 0.736864 alpha = 0.078
Epoch 1, iteration 150: loss = 0.794056 alpha = 0.098
Epoch 1, iteration 160: loss = 0.765706 alpha = 0.118
Epoch 1, iteration 170: loss = 0.803655 alpha = 0.138
Epoch 1, iteration 180: loss = 0.795937 alpha = 0.158
Epoch 1, iteration 190: loss = 0.780615 alpha = 0.178
Epoch 1, iteration 200: loss = 0.805658 alpha = 0.198
Epoch 1, iteration 210: loss = 0.823976 alpha = 0.218
Epoch 1, iteration 220: loss = 0.827669 alpha = 0.238
Epoch 1, iteration 230: loss = 0.854051 alpha = 0.258
Epoch 1, Test Loss: 0.662142 IoU Score: 0.337858
Epoch 2, iteration 10: loss = 0.724238 alpha = 0
Epoch 2, iteration 20: loss = 0.724877 alpha = 0
Epoch 2, iteration 30: loss = 0.711205 alpha = 0
Epoch 2, iteration 40: loss = 0.704355 alpha = 0
Epoch 2, iteration 50: loss = 0.721480 alpha = 0
Epoch 2, iteration 60: loss = 0.697828 alpha = 0
Epoch 2, iteration 70: loss = 0.720605 alpha = 0
Epoch 2, iteration 80: loss = 0.719805 alpha = 0
Epoch 2, iteration 90: loss = 0.724680 alpha = 0
Epoch 2, iteration 100: loss = 0.726747 alpha = 0
Epoch 2, iteration 110: loss = 0.716102 alpha = 0.018
Epoch 2, iteration 120: loss = 0.727058 alpha = 0.038
Epoch 2, iteration 130: loss = 0.756610 alpha = 0.058
Epoch 2, iteration 140: loss = 0.757866 alpha = 0.078
Epoch 2, iteration 150: loss = 0.783105 alpha = 0.098
Epoch 2, iteration 160: loss = 0.762674 alpha = 0.118
Epoch 2, iteration 170: loss = 0.799401 alpha = 0.138
Epoch 2, iteration 180: loss = 0.794460 alpha = 0.158
Epoch 2, iteration 190: loss = 0.823566 alpha = 0.178
Epoch 2, iteration 200: loss = 0.814431 alpha = 0.198
Epoch 2, iteration 210: loss = 0.824186 alpha = 0.218
Epoch 2, iteration 220: loss = 0.826407 alpha = 0.238
Epoch 2, iteration 230: loss = 0.839665 alpha = 0.258
Epoch 2, Test Loss: 0.676778 IoU Score: 0.323222
Epoch 3, iteration 10: loss = 0.716430 alpha = 0
Epoch 3, iteration 20: loss = 0.701242 alpha = 0
Epoch 3, iteration 30: loss = 0.723469 alpha = 0
Epoch 3, iteration 40: loss = 0.719385 alpha = 0
Epoch 3, iteration 50: loss = 0.709148 alpha = 0
Epoch 3, iteration 60: loss = 0.709012 alpha = 0
Epoch 3, iteration 70: loss = 0.729151 alpha = 0
Epoch 3, iteration 80: loss = 0.718438 alpha = 0
Epoch 3, iteration 90: loss = 0.717480 alpha = 0
Epoch 3, iteration 100: loss = 0.726638 alpha = 0
Epoch 3, iteration 110: loss = 0.727433 alpha = 0.018
Epoch 3, iteration 120: loss = 0.712104 alpha = 0.038
Epoch 3, iteration 130: loss = 0.727833 alpha = 0.058
Epoch 3, iteration 140: loss = 0.758031 alpha = 0.078
Epoch 3, iteration 150: loss = 0.769639 alpha = 0.098
Epoch 3, iteration 160: loss = 0.778451 alpha = 0.118
Epoch 3, iteration 170: loss = 0.779746 alpha = 0.138
Epoch 3, iteration 180: loss = 0.793857 alpha = 0.158
Epoch 3, iteration 190: loss = 0.814287 alpha = 0.178
Epoch 3, iteration 200: loss = 0.798008 alpha = 0.198
Epoch 3, iteration 210: loss = 0.855363 alpha = 0.218
Epoch 3, iteration 220: loss = 0.853951 alpha = 0.238
Epoch 3, iteration 230: loss = 0.855902 alpha = 0.258
Epoch 3, Test Loss: 0.676773 IoU Score: 0.323227
Epoch 4, iteration 10: loss = 0.708582 alpha = 0
Epoch 4, iteration 20: loss = 0.698956 alpha = 0
Epoch 4, iteration 30: loss = 0.727120 alpha = 0
Epoch 4, iteration 40: loss = 0.749607 alpha = 0
Epoch 4, iteration 50: loss = 0.726212 alpha = 0
Epoch 4, iteration 60: loss = 0.706905 alpha = 0
Epoch 4, iteration 70: loss = 0.728900 alpha = 0
Epoch 4, iteration 80: loss = 0.707840 alpha = 0
Epoch 4, iteration 90: loss = 0.729184 alpha = 0
Epoch 4, iteration 100: loss = 0.740524 alpha = 0
Epoch 4, iteration 110: loss = 0.732848 alpha = 0.018
Epoch 4, iteration 120: loss = 0.720003 alpha = 0.038
Epoch 4, iteration 130: loss = 0.727186 alpha = 0.058
Epoch 4, iteration 140: loss = 0.763042 alpha = 0.078
Epoch 4, iteration 150: loss = 0.748793 alpha = 0.098
Epoch 4, iteration 160: loss = 0.761530 alpha = 0.118
Epoch 4, iteration 170: loss = 0.786530 alpha = 0.138
Epoch 4, iteration 180: loss = 0.782219 alpha = 0.158
Epoch 4, iteration 190: loss = 0.815792 alpha = 0.178
Epoch 4, iteration 200: loss = 0.803635 alpha = 0.198
Epoch 4, iteration 210: loss = 0.813703 alpha = 0.218
Epoch 4, iteration 220: loss = 0.851401 alpha = 0.238
Epoch 4, iteration 230: loss = 0.864478 alpha = 0.258
Epoch 4, Test Loss: 0.676773 IoU Score: 0.323227
Epoch 5, iteration 10: loss = 0.722484 alpha = 0
Epoch 5, iteration 20: loss = 0.713378 alpha = 0
Epoch 5, iteration 30: loss = 0.725227 alpha = 0
Epoch 5, iteration 40: loss = 0.730513 alpha = 0
Epoch 5, iteration 50: loss = 0.713695 alpha = 0
Epoch 5, iteration 60: loss = 0.692115 alpha = 0
Epoch 5, iteration 70: loss = 0.721187 alpha = 0
Epoch 5, iteration 80: loss = 0.720090 alpha = 0
Epoch 5, iteration 90: loss = 0.715930 alpha = 0
Epoch 5, iteration 100: loss = 0.725694 alpha = 0
Epoch 5, iteration 110: loss = 0.703000 alpha = 0.018
Epoch 5, iteration 120: loss = 0.736896 alpha = 0.038
Epoch 5, iteration 130: loss = 0.760449 alpha = 0.058
Epoch 5, iteration 140: loss = 0.764113 alpha = 0.078
Epoch 5, iteration 150: loss = 0.754477 alpha = 0.098
Epoch 5, iteration 160: loss = 0.767645 alpha = 0.118
Epoch 5, iteration 170: loss = 0.805533 alpha = 0.138
Epoch 5, iteration 180: loss = 0.787242 alpha = 0.158
Epoch 5, iteration 190: loss = 0.814478 alpha = 0.178
Epoch 5, iteration 200: loss = 0.819716 alpha = 0.198
Epoch 5, iteration 210: loss = 0.818654 alpha = 0.218
Epoch 5, iteration 220: loss = 0.827820 alpha = 0.238
Epoch 5, iteration 230: loss = 0.854650 alpha = 0.258
Epoch 5, Test Loss: 0.676773 IoU Score: 0.323227
Training completed.
Model trained with iou loss and 1:3 ratio saved.
Ratio of labeled to unlabeled data is 1:3, but only labeled data is used here.
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.721252
Epoch 1, iteration 20: loss = 0.664132
Epoch 1, iteration 30: loss = 0.675054
Epoch 1, iteration 40: loss = 0.675905
Epoch 1, iteration 50: loss = 0.664379
Epoch 1, iteration 60: loss = 0.667670
Epoch 1, iteration 70: loss = 0.677811
Epoch 1, iteration 80: loss = 0.647502
Epoch 1, iteration 90: loss = 0.662668
Epoch 1, iteration 100: loss = 0.664375
Epoch 1, iteration 110: loss = 0.670352
Epoch 1, iteration 120: loss = 0.651620
Epoch 1, iteration 130: loss = 0.667217
Epoch 1, iteration 140: loss = 0.645515
Epoch 1, iteration 150: loss = 0.665668
Epoch 1, iteration 160: loss = 0.684121
Epoch 1, iteration 170: loss = 0.669449
Epoch 1, iteration 180: loss = 0.627232
Epoch 1, iteration 190: loss = 0.658480
Epoch 1, iteration 200: loss = 0.676441
Epoch 1, iteration 210: loss = 0.668614
Epoch 1, iteration 220: loss = 0.655595
Epoch 1, iteration 230: loss = 0.655623
Epoch 1, Test Loss: 0.662939 IoU Score: 0.337061
Epoch 2, iteration 10: loss = 0.703817
Epoch 2, iteration 20: loss = 0.681853
Epoch 2, iteration 30: loss = 0.703203
Epoch 2, iteration 40: loss = 0.665867
Epoch 2, iteration 50: loss = 0.664092
Epoch 2, iteration 60: loss = 0.676759
Epoch 2, iteration 70: loss = 0.673793
Epoch 2, iteration 80: loss = 0.659627
Epoch 2, iteration 90: loss = 0.657326
Epoch 2, iteration 100: loss = 0.667049
Epoch 2, iteration 110: loss = 0.669824
Epoch 2, iteration 120: loss = 0.665041
Epoch 2, iteration 130: loss = 0.657774
Epoch 2, iteration 140: loss = 0.660162
Epoch 2, iteration 150: loss = 0.664677
Epoch 2, iteration 160: loss = 0.650518
Epoch 2, iteration 170: loss = 0.670385
Epoch 2, iteration 180: loss = 0.662541
Epoch 2, iteration 190: loss = 0.673381
Epoch 2, iteration 200: loss = 0.665573
Epoch 2, iteration 210: loss = 0.663993
Epoch 2, iteration 220: loss = 0.660682
Epoch 2, iteration 230: loss = 0.667038
Epoch 2, Test Loss: 0.661099 IoU Score: 0.338901
Epoch 3, iteration 10: loss = 0.656491
Epoch 3, iteration 20: loss = 0.680425
Epoch 3, iteration 30: loss = 0.669125
Epoch 3, iteration 40: loss = 0.655184
Epoch 3, iteration 50: loss = 0.670450
Epoch 3, iteration 60: loss = 0.660996
Epoch 3, iteration 70: loss = 0.662506
Epoch 3, iteration 80: loss = 0.671213
Epoch 3, iteration 90: loss = 0.683185
Epoch 3, iteration 100: loss = 0.681195
Epoch 3, iteration 110: loss = 0.646252
Epoch 3, iteration 120: loss = 0.679029
Epoch 3, iteration 130: loss = 0.666216
Epoch 3, iteration 140: loss = 0.675071
Epoch 3, iteration 150: loss = 0.656081
Epoch 3, iteration 160: loss = 0.681073
Epoch 3, iteration 170: loss = 0.663668
Epoch 3, iteration 180: loss = 0.649295
Epoch 3, iteration 190: loss = 0.671655
Epoch 3, iteration 200: loss = 0.655989
Epoch 3, iteration 210: loss = 0.684248
Epoch 3, iteration 220: loss = 0.698050
Epoch 3, iteration 230: loss = 0.656399
Epoch 3, Test Loss: 0.671143 IoU Score: 0.328857
Epoch 4, iteration 10: loss = 0.663936
Epoch 4, iteration 20: loss = 0.689042
Epoch 4, iteration 30: loss = 0.655500
Epoch 4, iteration 40: loss = 0.685162
Epoch 4, iteration 50: loss = 0.687072
Epoch 4, iteration 60: loss = 0.685444
Epoch 4, iteration 70: loss = 0.680048
Epoch 4, iteration 80: loss = 0.670794
Epoch 4, iteration 90: loss = 0.672906
Epoch 4, iteration 100: loss = 0.681225
Epoch 4, iteration 110: loss = 0.676542
Epoch 4, iteration 120: loss = 0.697458
Epoch 4, iteration 130: loss = 0.942679
Epoch 4, iteration 140: loss = 0.999997
Epoch 4, iteration 150: loss = 0.999996
Epoch 4, iteration 160: loss = 0.999996
Epoch 4, iteration 170: loss = 0.999995
Epoch 4, iteration 180: loss = 0.999995
Epoch 4, iteration 190: loss = 0.999994
Epoch 4, iteration 200: loss = 0.999993
Epoch 4, iteration 210: loss = 0.999993
Epoch 4, iteration 220: loss = 0.999989
Epoch 4, iteration 230: loss = 0.999988
Epoch 4, Test Loss: 0.999984 IoU Score: 0.000016
Epoch 5, iteration 10: loss = 0.999980
Epoch 5, iteration 20: loss = 0.999964
Epoch 5, iteration 30: loss = 0.999750
Epoch 5, iteration 40: loss = 0.958309
Epoch 5, iteration 50: loss = 0.781942
Epoch 5, iteration 60: loss = 0.664926
Epoch 5, iteration 70: loss = 0.700044
Epoch 5, iteration 80: loss = 0.710459
Epoch 5, iteration 90: loss = 0.685539
Epoch 5, iteration 100: loss = 0.688898
Epoch 5, iteration 110: loss = 0.689344
Epoch 5, iteration 120: loss = 0.686362
Epoch 5, iteration 130: loss = 0.687452
Epoch 5, iteration 140: loss = 0.668045
Epoch 5, iteration 150: loss = 0.686145
Epoch 5, iteration 160: loss = 0.683416
Epoch 5, iteration 170: loss = 0.689932
Epoch 5, iteration 180: loss = 0.685043
Epoch 5, iteration 190: loss = 0.686769
Epoch 5, iteration 200: loss = 0.692468
Epoch 5, iteration 210: loss = 0.692186
Epoch 5, iteration 220: loss = 0.680676
Epoch 5, iteration 230: loss = 0.687346
Epoch 5, Test Loss: 0.677644 IoU Score: 0.322356
Training completed.
Model trained with iou loss and 1:3 ratio but labeled only saved.
num labeled_data: 613
num unlabeled_data: 3067
train labeled dataset: 613
train unlabeled dataset: 3067
test labeled dataset: 3669
train labeled loader: 613
train unlabeled loader: 3067
test labeled loader: 3669
Ratio of labeled to unlabeled data is 1:5
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.727288 alpha = 0
Epoch 1, iteration 20: loss = 0.722471 alpha = 0
Epoch 1, iteration 30: loss = 0.758108 alpha = 0
Epoch 1, iteration 40: loss = 0.692895 alpha = 0
Epoch 1, iteration 50: loss = 0.720538 alpha = 0
Epoch 1, iteration 60: loss = 0.692461 alpha = 0
Epoch 1, iteration 70: loss = 0.709868 alpha = 0
Epoch 1, iteration 80: loss = 0.713381 alpha = 0
Epoch 1, iteration 90: loss = 0.726573 alpha = 0
Epoch 1, iteration 100: loss = 0.711276 alpha = 0
Epoch 1, iteration 110: loss = 0.732501 alpha = 0.018
Epoch 1, iteration 120: loss = 0.723814 alpha = 0.038
Epoch 1, iteration 130: loss = 0.740132 alpha = 0.058
Epoch 1, iteration 140: loss = 0.745024 alpha = 0.078
Epoch 1, iteration 150: loss = 0.766673 alpha = 0.098
Epoch 1, Test Loss: 0.661654 IoU Score: 0.338346
Epoch 2, iteration 10: loss = 0.697566 alpha = 0
Epoch 2, iteration 20: loss = 0.712444 alpha = 0
Epoch 2, iteration 30: loss = 0.721450 alpha = 0
Epoch 2, iteration 40: loss = 0.724042 alpha = 0
Epoch 2, iteration 50: loss = 0.709863 alpha = 0
Epoch 2, iteration 60: loss = 0.737374 alpha = 0
Epoch 2, iteration 70: loss = 0.707958 alpha = 0
Epoch 2, iteration 80: loss = 0.714918 alpha = 0
Epoch 2, iteration 90: loss = 0.719510 alpha = 0
Epoch 2, iteration 100: loss = 0.740683 alpha = 0
Epoch 2, iteration 110: loss = 0.734887 alpha = 0.018
Epoch 2, iteration 120: loss = 0.748674 alpha = 0.038
Epoch 2, iteration 130: loss = 0.731855 alpha = 0.058
Epoch 2, iteration 140: loss = 0.740757 alpha = 0.078
Epoch 2, iteration 150: loss = 0.763622 alpha = 0.098
Epoch 2, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 3, iteration 10: loss = 0.733743 alpha = 0
Epoch 3, iteration 20: loss = 0.696726 alpha = 0
Epoch 3, iteration 30: loss = 0.699224 alpha = 0
Epoch 3, iteration 40: loss = 0.742820 alpha = 0
Epoch 3, iteration 50: loss = 0.722939 alpha = 0
Epoch 3, iteration 60: loss = 0.718951 alpha = 0
Epoch 3, iteration 70: loss = 0.714055 alpha = 0
Epoch 3, iteration 80: loss = 0.712156 alpha = 0
Epoch 3, iteration 90: loss = 0.710834 alpha = 0
Epoch 3, iteration 100: loss = 0.712512 alpha = 0
Epoch 3, iteration 110: loss = 0.713972 alpha = 0.018
Epoch 3, iteration 120: loss = 0.758715 alpha = 0.038
Epoch 3, iteration 130: loss = 0.752196 alpha = 0.058
Epoch 3, iteration 140: loss = 0.761131 alpha = 0.078
Epoch 3, iteration 150: loss = 0.756773 alpha = 0.098
Epoch 3, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 4, iteration 10: loss = 0.716618 alpha = 0
Epoch 4, iteration 20: loss = 0.722726 alpha = 0
Epoch 4, iteration 30: loss = 0.722720 alpha = 0
Epoch 4, iteration 40: loss = 0.726302 alpha = 0
Epoch 4, iteration 50: loss = 0.726618 alpha = 0
Epoch 4, iteration 60: loss = 0.734292 alpha = 0
Epoch 4, iteration 70: loss = 0.718895 alpha = 0
Epoch 4, iteration 80: loss = 0.713859 alpha = 0
Epoch 4, iteration 90: loss = 0.696712 alpha = 0
Epoch 4, iteration 100: loss = 0.738500 alpha = 0
Epoch 4, iteration 110: loss = 0.714994 alpha = 0.018
Epoch 4, iteration 120: loss = 0.729700 alpha = 0.038
Epoch 4, iteration 130: loss = 0.720096 alpha = 0.058
Epoch 4, iteration 140: loss = 0.760856 alpha = 0.078
Epoch 4, iteration 150: loss = 0.778718 alpha = 0.098
Epoch 4, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 5, iteration 10: loss = 0.717209 alpha = 0
Epoch 5, iteration 20: loss = 0.701119 alpha = 0
Epoch 5, iteration 30: loss = 0.721744 alpha = 0
Epoch 5, iteration 40: loss = 0.720880 alpha = 0
Epoch 5, iteration 50: loss = 0.737084 alpha = 0
Epoch 5, iteration 60: loss = 0.735496 alpha = 0
Epoch 5, iteration 70: loss = 0.733096 alpha = 0
Epoch 5, iteration 80: loss = 0.713677 alpha = 0
Epoch 5, iteration 90: loss = 0.714699 alpha = 0
Epoch 5, iteration 100: loss = 0.712159 alpha = 0
Epoch 5, iteration 110: loss = 0.719471 alpha = 0.018
Epoch 5, iteration 120: loss = 0.732513 alpha = 0.038
Epoch 5, iteration 130: loss = 0.745779 alpha = 0.058
Epoch 5, iteration 140: loss = 0.737260 alpha = 0.078
Epoch 5, iteration 150: loss = 0.775554 alpha = 0.098
Epoch 5, Test Loss: 0.677774 IoU Score: 0.322226
Training completed.
Model trained with iou loss and 1:5 ratio saved.
Ratio of labeled to unlabeled data is 1:5, but only labeled data is used here.
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.732589
Epoch 1, iteration 20: loss = 0.678274
Epoch 1, iteration 30: loss = 0.653339
Epoch 1, iteration 40: loss = 0.652229
Epoch 1, iteration 50: loss = 0.653743
Epoch 1, iteration 60: loss = 0.692657
Epoch 1, iteration 70: loss = 0.651875
Epoch 1, iteration 80: loss = 0.645452
Epoch 1, iteration 90: loss = 0.674570
Epoch 1, iteration 100: loss = 0.665712
Epoch 1, iteration 110: loss = 0.675830
Epoch 1, iteration 120: loss = 0.648808
Epoch 1, iteration 130: loss = 0.677602
Epoch 1, iteration 140: loss = 0.675103
Epoch 1, iteration 150: loss = 0.676477
Epoch 1, Test Loss: 0.661861 IoU Score: 0.338139
Epoch 2, iteration 10: loss = 0.674458
Epoch 2, iteration 20: loss = 0.694016
Epoch 2, iteration 30: loss = 0.695076
Epoch 2, iteration 40: loss = 0.677640
Epoch 2, iteration 50: loss = 0.686047
Epoch 2, iteration 60: loss = 0.687104
Epoch 2, iteration 70: loss = 0.699798
Epoch 2, iteration 80: loss = 0.678478
Epoch 2, iteration 90: loss = 0.689479
Epoch 2, iteration 100: loss = 0.681177
Epoch 2, iteration 110: loss = 0.666574
Epoch 2, iteration 120: loss = 0.675165
Epoch 2, iteration 130: loss = 0.666409
Epoch 2, iteration 140: loss = 0.682874
Epoch 2, iteration 150: loss = 0.665490
Epoch 2, Test Loss: 0.681868 IoU Score: 0.318132
Epoch 3, iteration 10: loss = 0.687161
Epoch 3, iteration 20: loss = 0.667464
Epoch 3, iteration 30: loss = 0.665580
Epoch 3, iteration 40: loss = 0.693448
Epoch 3, iteration 50: loss = 0.658968
Epoch 3, iteration 60: loss = 0.679118
Epoch 3, iteration 70: loss = 0.700327
Epoch 3, iteration 80: loss = 0.683125
Epoch 3, iteration 90: loss = 0.664648
Epoch 3, iteration 100: loss = 0.701881
Epoch 3, iteration 110: loss = 0.663350
Epoch 3, iteration 120: loss = 0.683410
Epoch 3, iteration 130: loss = 0.683528
Epoch 3, iteration 140: loss = 0.687310
Epoch 3, iteration 150: loss = 0.663328
Epoch 3, Test Loss: 0.676568 IoU Score: 0.323432
Epoch 4, iteration 10: loss = 0.679064
Epoch 4, iteration 20: loss = 0.671543
Epoch 4, iteration 30: loss = 0.702114
Epoch 4, iteration 40: loss = 0.674501
Epoch 4, iteration 50: loss = 0.657775
Epoch 4, iteration 60: loss = 0.701699
Epoch 4, iteration 70: loss = 0.687667
Epoch 4, iteration 80: loss = 0.694639
Epoch 4, iteration 90: loss = 0.678624
Epoch 4, iteration 100: loss = 0.690072
Epoch 4, iteration 110: loss = 0.654302
Epoch 4, iteration 120: loss = 0.690253
Epoch 4, iteration 130: loss = 0.688045
Epoch 4, iteration 140: loss = 0.695289
Epoch 4, iteration 150: loss = 0.684960
Epoch 4, Test Loss: 0.676558 IoU Score: 0.323442
Epoch 5, iteration 10: loss = 0.717731
Epoch 5, iteration 20: loss = 0.695410
Epoch 5, iteration 30: loss = 0.675181
Epoch 5, iteration 40: loss = 0.667398
Epoch 5, iteration 50: loss = 0.705826
Epoch 5, iteration 60: loss = 0.693349
Epoch 5, iteration 70: loss = 0.660062
Epoch 5, iteration 80: loss = 0.660203
Epoch 5, iteration 90: loss = 0.682407
Epoch 5, iteration 100: loss = 0.697918
Epoch 5, iteration 110: loss = 0.680925
Epoch 5, iteration 120: loss = 0.663909
Epoch 5, iteration 130: loss = 0.663609
Epoch 5, iteration 140: loss = 0.703089
Epoch 5, iteration 150: loss = 0.698711
Epoch 5, Test Loss: 0.676545 IoU Score: 0.323455
Training completed.
Model trained with iou loss and 1:5 ratio but labeled only saved.
num labeled_data: 334
num unlabeled_data: 3346
train labeled dataset: 334
train unlabeled dataset: 3346
test labeled dataset: 3669
train labeled loader: 334
train unlabeled loader: 3346
test labeled loader: 3669
Ratio of labeled to unlabeled data is 1:10
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.712703 alpha = 0
Epoch 1, iteration 20: loss = 0.695559 alpha = 0
Epoch 1, iteration 30: loss = 0.733370 alpha = 0
Epoch 1, iteration 40: loss = 0.705945 alpha = 0
Epoch 1, iteration 50: loss = 0.700252 alpha = 0
Epoch 1, iteration 60: loss = 0.708107 alpha = 0
Epoch 1, iteration 70: loss = 0.732983 alpha = 0
Epoch 1, iteration 80: loss = 0.695198 alpha = 0
Epoch 1, Test Loss: 0.654786 IoU Score: 0.345214
Epoch 2, iteration 10: loss = 0.698364 alpha = 0
Epoch 2, iteration 20: loss = 0.717455 alpha = 0
Epoch 2, iteration 30: loss = 0.735810 alpha = 0
Epoch 2, iteration 40: loss = 0.714417 alpha = 0
Epoch 2, iteration 50: loss = 0.708979 alpha = 0
Epoch 2, iteration 60: loss = 0.702549 alpha = 0
Epoch 2, iteration 70: loss = 0.716390 alpha = 0
Epoch 2, iteration 80: loss = 0.700140 alpha = 0
Epoch 2, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 3, iteration 10: loss = 0.713255 alpha = 0
Epoch 3, iteration 20: loss = 0.706315 alpha = 0
Epoch 3, iteration 30: loss = 0.718606 alpha = 0
Epoch 3, iteration 40: loss = 0.723196 alpha = 0
Epoch 3, iteration 50: loss = 0.706825 alpha = 0
Epoch 3, iteration 60: loss = 0.715465 alpha = 0
Epoch 3, iteration 70: loss = 0.689082 alpha = 0
Epoch 3, iteration 80: loss = 0.707548 alpha = 0
Epoch 3, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 4, iteration 10: loss = 0.714541 alpha = 0
Epoch 4, iteration 20: loss = 0.726723 alpha = 0
Epoch 4, iteration 30: loss = 0.716558 alpha = 0
Epoch 4, iteration 40: loss = 0.711365 alpha = 0
Epoch 4, iteration 50: loss = 0.711328 alpha = 0
Epoch 4, iteration 60: loss = 0.707841 alpha = 0
Epoch 4, iteration 70: loss = 0.723325 alpha = 0
Epoch 4, iteration 80: loss = 0.689396 alpha = 0
Epoch 4, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 5, iteration 10: loss = 0.715567 alpha = 0
Epoch 5, iteration 20: loss = 0.714154 alpha = 0
Epoch 5, iteration 30: loss = 0.735835 alpha = 0
Epoch 5, iteration 40: loss = 0.697419 alpha = 0
Epoch 5, iteration 50: loss = 0.729647 alpha = 0
Epoch 5, iteration 60: loss = 0.702858 alpha = 0
Epoch 5, iteration 70: loss = 0.696123 alpha = 0
Epoch 5, iteration 80: loss = 0.697832 alpha = 0
Epoch 5, Test Loss: 0.677774 IoU Score: 0.322226
Training completed.
Model trained with iou loss and 1:10 ratio saved.
Ratio of labeled to unlabeled data is 1:10, but only labeled data is used here.
Training with iou loss function..
Epoch 1, iteration 10: loss = 0.724530
Epoch 1, iteration 20: loss = 0.673988
Epoch 1, iteration 30: loss = 0.659001
Epoch 1, iteration 40: loss = 0.660378
Epoch 1, iteration 50: loss = 0.651855
Epoch 1, iteration 60: loss = 0.663323
Epoch 1, iteration 70: loss = 0.646233
Epoch 1, iteration 80: loss = 0.653063
Epoch 1, Test Loss: 0.655167 IoU Score: 0.344833
Epoch 2, iteration 10: loss = 0.679745
Epoch 2, iteration 20: loss = 0.672949
Epoch 2, iteration 30: loss = 0.666750
Epoch 2, iteration 40: loss = 0.682208
Epoch 2, iteration 50: loss = 0.669079
Epoch 2, iteration 60: loss = 0.693994
Epoch 2, iteration 70: loss = 0.683266
Epoch 2, iteration 80: loss = 0.659889
Epoch 2, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 3, iteration 10: loss = 0.670857
Epoch 3, iteration 20: loss = 0.658190
Epoch 3, iteration 30: loss = 0.667487
Epoch 3, iteration 40: loss = 0.676060
Epoch 3, iteration 50: loss = 0.671424
Epoch 3, iteration 60: loss = 0.680240
Epoch 3, iteration 70: loss = 0.692415
Epoch 3, iteration 80: loss = 0.667126
Epoch 3, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 4, iteration 10: loss = 0.677031
Epoch 4, iteration 20: loss = 0.681427
Epoch 4, iteration 30: loss = 0.670510
Epoch 4, iteration 40: loss = 0.669361
Epoch 4, iteration 50: loss = 0.671509
Epoch 4, iteration 60: loss = 0.686380
Epoch 4, iteration 70: loss = 0.667711
Epoch 4, iteration 80: loss = 0.672485
Epoch 4, Test Loss: 0.677774 IoU Score: 0.322226
Epoch 5, iteration 10: loss = 0.689089
Epoch 5, iteration 20: loss = 0.641187
Epoch 5, iteration 30: loss = 0.659817
Epoch 5, iteration 40: loss = 0.713650
Epoch 5, iteration 50: loss = 0.672935
Epoch 5, iteration 60: loss = 0.671414
Epoch 5, iteration 70: loss = 0.652141
Epoch 5, iteration 80: loss = 0.701055
Epoch 5, Test Loss: 0.677774 IoU Score: 0.322226
Training completed.
Model trained with iou loss and 1:10 ratio but labeled only saved.
